import streamlit as st
import os
import sys
import faiss
import numpy as np
import pickle
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pypdf import PdfReader
from io import BytesIO
from dotenv import load_dotenv
import requests
import google.generativeai as genai
from deep_translator import GoogleTranslator

# Load environment variables
load_dotenv()

# Configure Gemini API
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY and GEMINI_API_KEY != 'your_gemini_api_key_here':
    genai.configure(api_key=GEMINI_API_KEY)
    GEMINI_AVAILABLE = True
else:
    GEMINI_AVAILABLE = False

# Supported Languages (22 Indian Official Languages)
LANGUAGES = {
    'en': 'ğŸ‡¬ğŸ‡§ English',
    'hi': 'ğŸ‡®ğŸ‡³ à¤¹à¤¿à¤‚à¤¦à¥€ (Hindi)',
    'bn': 'ğŸ‡®ğŸ‡³ à¦¬à¦¾à¦‚à¦²à¦¾ (Bengali)',
    'te': 'ğŸ‡®ğŸ‡³ à°¤à±†à°²à±à°—à± (Telugu)',
    'mr': 'ğŸ‡®ğŸ‡³ à¤®à¤°à¤¾à¤ à¥€ (Marathi)',
    'ta': 'ğŸ‡®ğŸ‡³ à®¤à®®à®¿à®´à¯ (Tamil)',
    'ur': 'ğŸ‡®ğŸ‡³ Ø§Ø±Ø¯Ùˆ (Urdu)',
    'gu': 'ğŸ‡®ğŸ‡³ àª—à«àªœàª°àª¾àª¤à«€ (Gujarati)',
    'kn': 'ğŸ‡®ğŸ‡³ à²•à²¨à³à²¨à²¡ (Kannada)',
    'or': 'ğŸ‡®ğŸ‡³ à¬“à¬¡à¬¼à¬¿à¬† (Odia)',
    'ml': 'ğŸ‡®ğŸ‡³ à´®à´²à´¯à´¾à´³à´‚ (Malayalam)',
    'pa': 'ğŸ‡®ğŸ‡³ à¨ªà©°à¨œà¨¾à¨¬à©€ (Punjabi)',
    'as': 'ğŸ‡®ğŸ‡³ à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾ (Assamese)',
    'sa': 'ğŸ‡®ğŸ‡³ à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤ (Sanskrit)',
    'ne': 'ğŸ‡®ğŸ‡³ à¤¨à¥‡à¤ªà¤¾à¤²à¥€ (Nepali)',
    'sd': 'ğŸ‡®ğŸ‡³ Ø³Ù†ÚŒÙŠ (Sindhi)'
}

# Translation Helper Functions
def translate_text(text, source_lang='auto', target_lang='en'):
    """Translate text using deep-translator"""
    try:
        if source_lang == target_lang or (target_lang == 'en' and source_lang == 'auto'):
            return text
        
        translator = GoogleTranslator(source=source_lang, target=target_lang)
        translated = translator.translate(text)
        return translated
    except Exception as e:
        st.warning(f"âš ï¸ Translation error: {str(e)}. Showing original text.")
        return text

def translate_to_english(text, source_lang):
    """Translate user input to English for RAG processing"""
    if source_lang == 'en':
        return text
    return translate_text(text, source_lang=source_lang, target_lang='en')

def translate_from_english(text, target_lang):
    """Translate AI response from English to user's language"""
    if target_lang == 'en':
        return text
    return translate_text(text, source_lang='en', target_lang=target_lang)

# Page configuration
st.set_page_config(
    page_title="MeghSutra AI - Climate Intelligence",
    page_icon="ğŸŒ¦ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for premium design
st.markdown("""
<style>
    /* Import Google Font */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap');
    
    /* Global Styles */
    * {
        font-family: 'Inter', sans-serif;
    }
    
    /* Main Background - Force gradient everywhere */
    .stApp {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%) !important;
    }
    
    /* Remove ALL black backgrounds */
    .main .block-container {
        background: transparent !important;
        padding-bottom: 0 !important;
    }
    
    .main {
        background: transparent !important;
    }
    
    section[data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1e293b 0%, #0f172a 100%) !important;
    }
    
    /* Remove bottom padding/margin that creates black space */
    .block-container {
        padding-bottom: 1rem !important;
        margin-bottom: 0 !important;
    }
    
    /* Hide Streamlit menu and footer */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Hero Section - Compact & Left Aligned */
    .hero-section {
        background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);
        padding: 15px 25px;
        border-radius: 15px;
        box-shadow: 0 10px 30px rgba(59, 130, 246, 0.2);
        animation: fadeIn 0.8s ease-in;
        text-align: left;
    }
    
    .hero-title {
        font-size: 1.6rem;
        font-weight: 700;
        color: white;
        margin-bottom: 3px;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.2);
    }
    
    .hero-subtitle {
        font-size: 0.85rem;
        color: #e0e7ff;
        font-weight: 300;
    }
    
    /* Navigation Cards - Compact & Right-aligned */
    .nav-card {
        background: rgba(255, 255, 255, 0.05);
        backdrop-filter: blur(10px);
        border: 2px solid rgba(255, 255, 255, 0.1);
        border-radius: 10px;
        padding: 8px 16px;
        cursor: pointer;
        transition: all 0.3s ease;
        text-align: center;
        min-width: 100px;
        font-size: 0.85rem;
    }
    
    .nav-card.active {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
        border-color: #3b82f6;
        box-shadow: 0 6px 20px rgba(59, 130, 246, 0.4);
    }
    
    /* Compact hover effects */
    .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 20px rgba(59, 130, 246, 0.3);
    }
    
    /* Stats Cards */
    .stats-card {
        background: rgba(255, 255, 255, 0.05);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.1);
        border-radius: 15px;
        padding: 1.5rem;
        transition: all 0.3s ease;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    }
    
    .stats-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 40px rgba(59, 130, 246, 0.2);
        border-color: rgba(59, 130, 246, 0.3);
    }
    
    .stats-number {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #60a5fa 0%, #3b82f6 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    
    .stats-label {
        font-size: 0.9rem;
        color: #94a3b8;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    /* Chat Messages */
    .stChatMessage {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 15px;
        border: 1px solid rgba(255, 255, 255, 0.1);
        padding: 1rem;
        margin-bottom: 1rem;
    }
    
    /* Chat Input Area Styling */
    .stChatInputContainer {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 15px;
        padding: 10px;
    }
    
    /* Buttons */
    .stButton > button {
        background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(59, 130, 246, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(59, 130, 246, 0.4);
    }
    
    /* Sidebar */
    .css-1d391kg, [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1e293b 0%, #0f172a 100%);
    }
    
    /* Animations */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .fade-in {
        animation: fadeIn 0.6s ease-in;
    }
    
    /* Text Colors */
    h1, h2, h3, h4, h5, h6 {
        color: #f1f5f9 !important;
    }
    
    p, li, span {
        color: #cbd5e1 !important;
    }
    
    /* Input Fields */
    .stTextInput > div > div > input {
        background: rgba(255, 255, 255, 0.05);
        border: 1px solid rgba(255, 255, 255, 0.1);
        border-radius: 10px;
        color: white;
    }
    
    /* File Uploader */
    .stFileUploader {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 15px;
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# RAG Pipeline Class
class RAGPipeline:
    def __init__(self, vector_store_path="vector_store", embedding_model="all-MiniLM-L6-v2"):
        self.embedding_model = SentenceTransformer(embedding_model)
        self.vector_store_path = vector_store_path
        self.index = None
        self.chunks = None
        self.load_vector_store()
    
    def load_vector_store(self):
        # Updated to match actual vector store file names
        index_path = os.path.join(self.vector_store_path, "knowledge.index")
        chunks_path = os.path.join(self.vector_store_path, "metadata.pkl")
        
        if os.path.exists(index_path) and os.path.exists(chunks_path):
            try:
                self.index = faiss.read_index(index_path)
                with open(chunks_path, 'rb') as f:
                    self.chunks = pickle.load(f)
                print(f"âœ… Loaded vector store: {len(self.chunks)} chunks")
            except Exception as e:
                print(f"âŒ Error loading vector store: {e}")
                self.index = None
                self.chunks = None
        else:
            print(f"âš ï¸ Vector store not found at {self.vector_store_path}")
    
    def retrieve(self, query, top_k=3):
        if self.index is None or self.chunks is None:
            return []
        
        query_embedding = self.embedding_model.encode([query])
        distances, indices = self.index.search(np.array(query_embedding).astype('float32'), top_k)
        
        results = []
        for idx in indices[0]:
            if idx < len(self.chunks):
                results.append(self.chunks[idx])
        return results
    
    def generate(self, query, context):
        if not context:
            return "No relevant information found."
        
        # Fixed: chunks use 'content' key, not 'text'
        context_text = "\n\n".join([chunk.get('content', chunk.get('text', '')) for chunk in context])
        
        if GEMINI_AVAILABLE:
            try:
                # Fixed: Use valid model name
                model = genai.GenerativeModel('gemini-1.5-flash')
                prompt = f"""Based on the following context, answer the question concisely and accurately.

Context:
{context_text}

Question: {query}

Answer:"""
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                st.warning(f"Gemini API error: {str(e)}. Showing document excerpts instead.")
        
        # Fallback to document excerpts
        return f"**Relevant Information:**\n\n{context_text[:500]}..."

# Helper Functions
def load_main_pipeline():
    return RAGPipeline()

@st.cache_data
def load_rainfall_data():
    try:
        df = pd.read_csv("data/master_rainfall_india.csv")
        return df
    except:
        return None

def create_temp_pipeline_from_file(uploaded_file):
    pdf_reader = PdfReader(BytesIO(uploaded_file.read()))
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = text_splitter.split_text(text)
    
    pipeline = RAGPipeline()
    embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
    embeddings = embedding_model.encode(chunks)
    
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings).astype('float32'))
    
    pipeline.index = index
    pipeline.chunks = [{"text": chunk, "source_file": uploaded_file.name} for chunk in chunks]
    
    return pipeline

# Hero Section
def render_hero():
    st.markdown("""
    <div class="hero-section fade-in">
        <div class="hero-title">ğŸŒ¦ï¸ MeghSutra AI</div>
        <div class="hero-subtitle">Climate Intelligence Platform</div>
    </div>
    """, unsafe_allow_html=True)

# Navigation Cards - Compact (for Sidebar)
def render_navigation():
    if 'active_page' not in st.session_state:
        st.session_state.active_page = 'Chat'
    
    nav_items = [
        {'name': 'Chat', 'icon': 'ğŸ’¬'},
        {'name': 'Dashboard', 'icon': 'ğŸ“Š'},
        {'name': 'Explorer', 'icon': 'ğŸ—ºï¸'}
    ]
    
    for item in nav_items:
        if st.button(
            f"{item['icon']} {item['name']}",
            key=f"nav_{item['name']}",
            use_container_width=True,
            type="primary" if st.session_state.active_page == item['name'] else "secondary"
        ):
            st.session_state.active_page = item['name']
            st.rerun()

# Stats Cards
def render_stats():
    df = load_rainfall_data()
    
    # Rendered in sidebar for better focus
    st.markdown("### ğŸ“ˆ Project Metrics")
    
    years = df['Year'].nunique() if df is not None else 120
    ai_status = "Active" if GEMINI_AVAILABLE else "Docs Mode"
    ai_icon = "âœ…" if GEMINI_AVAILABLE else "ğŸ“–"
    
    stats = [
        ("36", "Regions Covered"),
        (f"{years}+", "Years of Data"),
        ("22", "Languages"),
        (ai_icon, f"AI {ai_status}")
    ]
    
    # Display stats in 2x2 grid in sidebar or vertical stack
    for val, label in stats:
        st.markdown(f"""
        <div class="stats-card fade-in" style="margin-bottom: 10px; padding: 12px;">
            <div class="stats-number" style="font-size: 1.6rem; margin-bottom: 0;">{val}</div>
            <div class="stats-label" style="font-size: 0.75rem;">{label}</div>
        </div>
        """, unsafe_allow_html=True)

# Main App
def main():
    # Initialize Session State
    if 'active_pipeline' not in st.session_state:
        st.session_state.active_pipeline = load_main_pipeline()
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'active_page' not in st.session_state:
        st.session_state.active_page = 'Chat'

    # Sidebar with Navigation
    with st.sidebar:
        st.markdown("### ğŸŒ¦ï¸ MeghSutra AI")
        st.markdown("---")
        
        # Language Selector
        st.markdown("#### ğŸŒ Language / à¤­à¤¾à¤·à¤¾")
        if 'language' not in st.session_state:
            st.session_state.language = 'en'
        
        selected_language = st.selectbox(
            "Select your language",
            options=list(LANGUAGES.keys()),
            format_func=lambda x: LANGUAGES[x],
            key='language_selector',
            index=list(LANGUAGES.keys()).index(st.session_state.language)
        )
        
        if selected_language != st.session_state.language:
            st.session_state.language = selected_language
            st.success(f"Language changed to {LANGUAGES[selected_language]}")
            st.rerun()
        
        st.markdown("---")
        
        # Navigation Cards in Sidebar
        st.markdown("#### Navigation")
        render_navigation()
        
        st.markdown("---")
        
        # Project Metrics
        render_stats()
        
        st.markdown("---")
        st.markdown("### ğŸ›ï¸ Control Panel")
        
        if GEMINI_AVAILABLE:
            st.success("âœ… Gemini AI Connected")
        else:
            st.warning("âš ï¸ Using Document Mode")
            with st.expander("ğŸ“– Enable AI Summaries"):
                st.markdown("""
                1. **Get Free API Key**: Visit [Google AI Studio](https://aistudio.google.com/app/apikey)
                2. **Create `.env` file** in project folder
                3. **Add**: `GEMINI_API_KEY=your_key_here`
                4. **Restart** this app
                
                âœ¨ Gemini API is FREE and instant!
                """)
        
        st.markdown("---")
        st.markdown("### ğŸ“š Knowledge Base")
        
        if st.button("ğŸŒ Use Main Climate Database", use_container_width=True):
            st.session_state.active_pipeline = load_main_pipeline()
            st.session_state.messages = []
            st.success("Switched to main climate database.")
    
    # Main content area with header
    render_hero()
    
    # Split View: Chat on left, Content on right
    if st.session_state.active_page == 'Chat':
        # Full width for chat only
        render_chat_tab()
    else:
        # Split view: Chat panel (left) + Content (right)
        chat_col, content_col = st.columns([1, 2])
        
        with chat_col:
            st.markdown("### ğŸ’¬ Quick Chat")
            render_chat_panel()
        
        with content_col:
            if st.session_state.active_page == 'Dashboard':
                render_dashboard_tab()
            elif st.session_state.active_page == 'Explorer':
                render_region_explorer_tab()

def render_chat_tab():
    st.markdown("### ğŸ’¬ Chat with MeghSutra AI")
    
    render_chat_panel()

def render_chat_panel():
    """Reusable chat panel for split view"""
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    if prompt := st.chat_input("Ask a question about climate data..."):
        if not st.session_state.active_pipeline:
            st.warning("Please load a knowledge base first.")
        else:
            # Get user's selected language
            user_lang = st.session_state.get('language', 'en')
            
            # Store original prompt in user's language
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    pipeline = st.session_state.active_pipeline
                    
                    # Translate query to English for RAG processing
                    if user_lang != 'en':
                        english_query = translate_to_english(prompt, user_lang)
                    else:
                        english_query = prompt
                    
                    # Process with RAG pipeline in English
                    context = pipeline.retrieve(english_query)
                    if not context:
                        response_english = "I couldn't find relevant information in the document to answer that."
                    else:
                        answer = pipeline.generate(english_query, context)
                        sources = set(chunk['source_file'] for chunk in context if 'source_file' in chunk)
                        if sources:
                            response_english = f"{answer}\n\n**Sources:**\n- " + "\n- ".join(sources)
                        else:
                            response_english = answer
                    
                    # Translate response back to user's language
                    if user_lang != 'en':
                        response_text = translate_from_english(response_english, user_lang)
                    else:
                        response_text = response_english
                    
                    st.markdown(response_text)
            
            st.session_state.messages.append({"role": "assistant", "content": response_text})

def render_dashboard_tab():
    st.markdown("### ğŸ“Š Interactive Rainfall Dashboard")
    
    df = load_rainfall_data()
    
    if df is None:
        st.error("Rainfall data not found. Please ensure `data/master_rainfall_india.csv` exists.")
        return
    
    # Filters
    col1, col2 = st.columns(2)
    
    with col1:
        regions = sorted(df['Subdivision'].unique())
        selected_region = st.selectbox("Select Region", regions, index=0)
    
    with col2:
        year_range = st.slider("Year Range", 
                               int(df['Year'].min()), 
                               int(df['Year'].max()), 
                               (1950, 2023))
    
    # Filter data
    filtered_df = df[(df['Subdivision'] == selected_region) & 
                     (df['Year'] >= year_range[0]) & 
                     (df['Year'] <= year_range[1])]
    
    # Annual Rainfall Trend
    st.markdown("#### Annual Rainfall Trend")
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=filtered_df['Year'],
        y=filtered_df['Annual'],
        mode='lines+markers',
        name='Annual Rainfall',
        line=dict(color='#3b82f6', width=3),
        marker=dict(size=6)
    ))
    
    # Add rolling average
    if len(filtered_df) > 10:
        filtered_df['Rolling_Avg'] = filtered_df['Annual'].rolling(window=10).mean()
        fig.add_trace(go.Scatter(
            x=filtered_df['Year'],
            y=filtered_df['Rolling_Avg'],
            mode='lines',
            name='10-Year Average',
            line=dict(color='#f59e0b', width=2, dash='dash')
        ))
    
    fig.update_layout(
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        height=400,
        xaxis_title="Year",
        yaxis_title="Rainfall (mm)",
        hovermode='x unified'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Monthly Distribution
    st.markdown("#### Monthly Rainfall Distribution (Latest Year)")
    latest_year_data = filtered_df[filtered_df['Year'] == filtered_df['Year'].max()].iloc[0]
    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    monthly_values = [latest_year_data[month] for month in months]
    
    fig2 = go.Figure(data=[
        go.Bar(
            x=months,
            y=monthly_values,
            marker=dict(
                color=monthly_values,
                colorscale='Blues',
                showscale=True
            )
        )
    ])
    
    fig2.update_layout(
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        height=350,
        xaxis_title="Month",
        yaxis_title="Rainfall (mm)"
    )
    st.plotly_chart(fig2, use_container_width=True)
    
    # Statistics
    col1, col2, col3 = st.columns(3)
    with col1:
        avg_rainfall = filtered_df['Annual'].mean()
        st.metric("Average Annual Rainfall", f"{avg_rainfall:.1f} mm")
    with col2:
        max_rainfall = filtered_df['Annual'].max()
        max_year = filtered_df[filtered_df['Annual'] == max_rainfall]['Year'].values[0]
        st.metric("Maximum Rainfall", f"{max_rainfall:.1f} mm", f"in {max_year}")
    with col3:
        min_rainfall = filtered_df['Annual'].min()
        min_year = filtered_df[filtered_df['Annual'] == min_rainfall]['Year'].values[0]
        st.metric("Minimum Rainfall", f"{min_rainfall:.1f} mm", f"in {min_year}")

def render_region_explorer_tab():
    st.markdown("### ğŸ—ºï¸ Explore Indian Climate Regions")
    
    df = load_rainfall_data()
    
    if df is None:
        st.error("Rainfall data not found.")
        return
    
    # Get latest year data for all regions
    latest_year = df['Year'].max()
    latest_data = df[df['Year'] == latest_year]
    
    # Create comparison chart
    st.markdown(f"#### Regional Comparison ({latest_year})")
    
    fig = px.bar(
        latest_data.sort_values('Annual', ascending=False).head(15),
        x='Subdivision',
        y='Annual',
        title=f"Top 15 Regions by Annual Rainfall",
        color='Annual',
        color_continuous_scale='Blues'
    )
    
    fig.update_layout(
        template='plotly_dark',
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        height=500,
        xaxis_title="Region",
        yaxis_title="Annual Rainfall (mm)",
        xaxis_tickangle=-45
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Region Details
    st.markdown("#### Region Details")
    selected_regions = st.multiselect(
        "Select regions to compare",
        sorted(df['Subdivision'].unique()),
        default=[sorted(df['Subdivision'].unique())[0]]
    )
    
    if selected_regions:
        comparison_df = df[df['Subdivision'].isin(selected_regions)]
        
        fig2 = go.Figure()
        for region in selected_regions:
            region_data = comparison_df[comparison_df['Subdivision'] == region]
            fig2.add_trace(go.Scatter(
                x=region_data['Year'],
                y=region_data['Annual'],
                mode='lines',
                name=region
            ))
        
        fig2.update_layout(
            template='plotly_dark',
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            height=400,
            xaxis_title="Year",
            yaxis_title="Annual Rainfall (mm)",
            hovermode='x unified'
        )
        st.plotly_chart(fig2, use_container_width=True)

def render_documents_tab():
    st.markdown("### ğŸ“‘ Climate Knowledge Base")
    
    st.markdown("""
    **Available Documents:**
    
    Our knowledge base includes comprehensive climate data and research:
    
    - ğŸŒ **IPCC Climate Reports** - Latest findings on global climate change
    - ğŸ“Š **Indian Rainfall Data** - 120+ years of historical rainfall records
    - ğŸŒ¾ **Agricultural Impact Studies** - Climate effects on Indian agriculture
    - ğŸ”¬ **Research Papers** - Peer-reviewed climate science publications
    
    **How to Use:**
    1. Navigate to the **Chat** tab to ask questions
    2. Upload your own PDF documents in the sidebar
    3. Explore the **Dashboard** for visual insights
    4. Compare regions in the **Region Explorer**
    """)
    
    # Show document stats
    docs_path = "documents"
    if os.path.exists(docs_path):
        pdf_files = [f for f in os.listdir(docs_path) if f.endswith('.pdf')]
        
        st.markdown(f"#### ğŸ“š {len(pdf_files)} Documents Indexed")
        
        for pdf in pdf_files:
            with st.expander(f"ğŸ“„ {pdf}"):
                file_path = os.path.join(docs_path, pdf)
                file_size = os.path.getsize(file_path) / 1024  # KB
                st.write(f"**Size:** {file_size:.1f} KB")
                st.write(f"**Path:** `{file_path}`")

if __name__ == "__main__":
    main()
